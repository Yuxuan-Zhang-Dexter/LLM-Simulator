{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "import os\n",
    "from typing import Literal, Tuple, Dict, Any\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "from monitor import ModelMemoryMonitorCPU\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Available Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load Models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current Available Device: {device}\")\n",
    "use_amp = amp_supported = torch.cuda.is_available() and torch.cuda.get_device_capability(0) >= (7, 0)\n",
    "tinyllama_model_name = \"TinyLlama/TinyLlama-1.1B-step-50K-105b\"\n",
    "llama7b_model_name = \"NousResearch/Llama-2-7b-hf\"\n",
    "# local_model_dir = './model_cache'\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"NousResearch/Llama-2-7b-hf\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"NousResearch/Llama-2-7b-hf\", torch_dtype=torch.float16).to(device)\n",
    "# Load model directly\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-step-50K-105b\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-step-50K-105b\",   torch_dtype=torch.float16).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference: Memory and Max Memory Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = AutoConfig.from_pretrained(\"Tinyllama/Tinyllama-1.1B-step-50K-105b\")\n",
    "\n",
    "# hidden_size = config.hidden_size\n",
    "# eos_token_id = config.eos_token_id\n",
    "# max_position_embeddings = config.max_position_embeddings\n",
    "\n",
    "# print(\"Hidden Size:\", hidden_size)\n",
    "# print(\"EOS Token ID:\", eos_token_id)\n",
    "# print(\"Max Position Embeddings:\", max_position_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "b = 1 # batch size\n",
    "s = 1 # sequence length\n",
    "max_s = 4096 # max sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ModelMemoryUtilities:\n",
    "    @staticmethod\n",
    "    def convert_memory(memory: int, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> float:\n",
    "        \"\"\"Convert memory to the specified unit.\"\"\"\n",
    "        if memory_unit == 'mb':\n",
    "            return memory / 1048576  # Convert bytes to MB\n",
    "        elif memory_unit == 'gb':\n",
    "            return memory / 1073741824  # Convert bytes to GB\n",
    "        return memory  # Default to bytes\n",
    "\n",
    "    @staticmethod\n",
    "    def get_logits(model_output) -> torch.Tensor:\n",
    "        \"\"\"Extract logits from model output, supporting various output formats.\"\"\"\n",
    "        if hasattr(model_output, 'logits'):\n",
    "            return model_output.logits\n",
    "        elif isinstance(model_output, torch.Tensor):\n",
    "            return model_output\n",
    "        else:\n",
    "            raise ValueError(\"Model output does not contain logits or is not a tensor.\")\n",
    "        \n",
    "    @staticmethod\n",
    "    def measure_cpu_memory():\n",
    "        \"\"\"Measure CPU memory usage in bytes.\"\"\"\n",
    "        return psutil.Process().memory_info().rss\n",
    "\n",
    "    @staticmethod\n",
    "    def draw_memory_lines(prev_memory: int, cur_memory_lst: list, peak_memory_lst: list = None, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte'):\n",
    "        \"\"\"Plot memory usage over iterations.\"\"\"\n",
    "        conv_prev_memory = ModelMemoryUtilities.convert_memory(prev_memory, memory_unit)\n",
    "        if peak_memory_lst is not None:\n",
    "            conv_peak_memory = [ModelMemoryUtilities.convert_memory(peak, memory_unit) for peak in peak_memory_lst]\n",
    "        conv_cur_memory = [ModelMemoryUtilities.convert_memory(cur, memory_unit) for cur in cur_memory_lst]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        iterations = range(len(cur_memory_lst))\n",
    "\n",
    "        # Baseline memory line\n",
    "        plt.axhline(y=conv_prev_memory, color='gray', linestyle='--', linewidth=1.5, label=f'Baseline ({conv_prev_memory:.2f} {memory_unit.upper()})')\n",
    "\n",
    "        # Peak and current memory lines\n",
    "        if peak_memory_lst is not None:\n",
    "            plt.plot(iterations, conv_peak_memory, label='Peak Memory', color='#FF5733', linewidth=2.5, linestyle='-', marker='o', markersize=5, alpha=0.85)\n",
    "        plt.plot(iterations, conv_cur_memory, label='Current Memory', color='#3498DB', linewidth=2.5, linestyle='-', marker='x', markersize=5, alpha=0.85)\n",
    "\n",
    "        # Labels and title\n",
    "        plt.xlabel(\"Iterations\", fontsize=12)\n",
    "        plt.ylabel(f\"Memory Usage ({memory_unit.upper()})\", fontsize=12)\n",
    "        plt.title(\"Memory Usage per Iteration\", fontsize=16, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.7)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    @staticmethod\n",
    "    def draw_memory_from_dict(memory_dict: Dict[str, Any], memory_unit: Literal['byte', 'mb', 'gb'] = 'gb'):\n",
    "        \"\"\"\n",
    "        Draw a memory usage plot with fixed lines for 'model_loading' and 'max_peak_memory', and dynamic lines\n",
    "        for each stage list found in the dictionary.\n",
    "        \n",
    "        :param memory_dict: Dictionary containing memory usage for different stages and fixed values.\n",
    "        :param memory_unit: The unit for memory display ('byte', 'mb', 'gb').\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Extract and plot fixed lines for 'model_loading' and any 'max_peak_memory'\n",
    "        fixed_lines = {key: ModelMemoryUtilities.convert_memory(value, memory_unit) for key, value in memory_dict.items()\n",
    "                       if 'max_peak_memory' in key or key == 'model_loading'}\n",
    "        for name, value in fixed_lines.items():\n",
    "            plt.axhline(y=value, linestyle='--', linewidth=1.5, label=f\"{name} ({value:.2f} {memory_unit.upper()})\")\n",
    "\n",
    "        # Plot dynamic lines for each memory stage list (e.g., forward_pass, backward_pass, optimize_model)\n",
    "        dynamic_lines = {key: [ModelMemoryUtilities.convert_memory(val, memory_unit) for val in values] for key, values in memory_dict.items() if isinstance(values, list)}\n",
    "        iterations = range(len(next(iter(dynamic_lines.values()))))  # Define iterations based on list length\n",
    "\n",
    "        for stage_name, memory_values in dynamic_lines.items():\n",
    "            plt.plot(iterations, memory_values, label=f'{stage_name.capitalize()} Memory', marker='o', markersize=5, alpha=0.85)\n",
    "\n",
    "        # Labels and title\n",
    "        plt.xlabel(\"Iterations\", fontsize=12)\n",
    "        plt.ylabel(f\"Memory Usage ({memory_unit.upper()})\", fontsize=12)\n",
    "        plt.title(\"Memory Consumption per Iteration by Stage\", fontsize=16, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMemoryMonitor:\n",
    "    def __init__(self, model_name, batch_size=1, max_seq_len=4096, torch_dtype=torch.float16, use_amp=False, device=\"cuda\"):\n",
    "        \"\"\"\n",
    "        Initialize ModelMemoryMonitor for tracking memory usage in inference and training.\n",
    "\n",
    "        Args:\n",
    "            model_name (str): Model name or path.\n",
    "            batch_size (int): Number of samples in a batch.\n",
    "            max_seq_len (int): Maximum sequence length.\n",
    "            torch_dtype (torch.dtype): Data type (e.g., torch.float16).\n",
    "            use_amp (bool): If True, enables mixed precision inference.\n",
    "            device (str): Device for inference ('cuda' or 'cpu').\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.torch_dtype = torch_dtype\n",
    "        self.device = device\n",
    "        self.use_amp = use_amp\n",
    "        self.batch_size = batch_size\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(self.model_name, torch_dtype=self.torch_dtype).to(device)\n",
    "\n",
    "        # Set pad_token to eos_token if no padding token is available\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "    def simulate_input_ids(self, sequence_length: int, only_padding=False):\n",
    "        \"\"\"\n",
    "        Generate dummy input IDs for a given sequence length.\n",
    "\n",
    "        Args:\n",
    "            sequence_length (int): Target sequence length.\n",
    "            only_padding (bool): If True, generate only padding tokens.\n",
    "\n",
    "        Returns:\n",
    "            dict: Input IDs and attention masks.\n",
    "        \"\"\"\n",
    "        dummy_text = \"\" if only_padding else \" \".join([\"token\"] * int(sequence_length * 1.5))\n",
    "        inputs = self.tokenizer(dummy_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_seq_len)\n",
    "        inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "        \n",
    "        actual_length = inputs[\"input_ids\"].shape[1]\n",
    "        if actual_length != sequence_length:\n",
    "            print(f\"Warning: Expected sequence length ({sequence_length}) does not match actual input length ({actual_length}).\")\n",
    "\n",
    "        attention_mask_sum = inputs[\"attention_mask\"].sum().item()\n",
    "        if attention_mask_sum != sequence_length:\n",
    "            print(f\"Warning: Attention mask sum ({attention_mask_sum}) does not match expected sequence length ({sequence_length}).\")\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def test_cuda_forward_memory(self, sample_inputs, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> Tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        Measure memory usage during a forward pass.\n",
    "\n",
    "        Args:\n",
    "            sample_inputs (dict): Model input data.\n",
    "            memory_unit (str): Unit for memory display.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Previous, peak, and current memory in specified unit.\n",
    "        \"\"\"\n",
    "        self.model.to(\"cpu\")  # Move model to CPU to measure existing memory reliably\n",
    "        exist_memory = torch.cuda.memory_allocated(self.device)\n",
    "        self.model.to(self.device)  # Move model back to GPU\n",
    "        self.model.eval()\n",
    "\n",
    "        prev_memory = torch.cuda.memory_allocated(self.device)\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = self.model(**sample_inputs)\n",
    "            output_sum = ModelMemoryUtilities.get_logits(output).sum()\n",
    "        \n",
    "        peak_memory = torch.cuda.max_memory_allocated(self.device) - exist_memory\n",
    "        cur_memory = torch.cuda.memory_allocated(self.device) - exist_memory\n",
    "\n",
    "        prev_memory = ModelMemoryUtilities.convert_memory(prev_memory - exist_memory, memory_unit)\n",
    "        peak_memory = ModelMemoryUtilities.convert_memory(peak_memory, memory_unit)\n",
    "        cur_memory = ModelMemoryUtilities.convert_memory(cur_memory, memory_unit)\n",
    "\n",
    "        print(f\"Previous Memory: {prev_memory:.2f} {memory_unit.upper()}; Peak Memory: {peak_memory:.2f} {memory_unit.upper()}; Current Memory: {cur_memory:.2f} {memory_unit.upper()}\")\n",
    "\n",
    "        return prev_memory, peak_memory, cur_memory\n",
    "    \n",
    "    def test_cuda_iterative_inference_memory(self, prompt: str, max_iters: int = 100, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> Tuple[float, list, list]:\n",
    "        \"\"\"\n",
    "        Estimate memory usage during iterative token-by-token generation.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): Initial prompt for generation.\n",
    "            max_iters (int): Maximum number of iterations (tokens) to generate.\n",
    "            memory_unit (Literal['byte', 'mb', 'gb']): Unit for memory measurement ('byte', 'mb', 'gb').\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, list, list]: Initial memory, list of peak memory per iteration, list of current memory per iteration.\n",
    "        \"\"\"\n",
    "        # Move model to CPU to measure existing memory reliably\n",
    "        self.model.to(\"cpu\")\n",
    "        exist_memory = torch.cuda.memory_allocated(self.device)\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "        # Initial memory state before starting the generation loop\n",
    "        prev_memory = torch.cuda.memory_allocated(self.device)\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_seq_len)\n",
    "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
    "\n",
    "        # Lists to track memory usage across iterations\n",
    "        peak_memory_lst, cur_memory_lst = [], []\n",
    "\n",
    "        for i in range(max_iters):\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                if self.use_amp:\n",
    "                    with torch.amp.autocast(device_type=str(self.device)):\n",
    "                        outputs = self.model.generate(\n",
    "                            input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            max_length=input_ids.shape[1] + 1,\n",
    "                            eos_token_id=self.tokenizer.eos_token_id,\n",
    "                            pad_token_id=self.tokenizer.eos_token_id,\n",
    "                            do_sample=False\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model.generate(\n",
    "                        input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        max_length=input_ids.shape[1] + 1,\n",
    "                        eos_token_id=self.tokenizer.eos_token_id,\n",
    "                        pad_token_id=self.tokenizer.eos_token_id,\n",
    "                        do_sample=False\n",
    "                    )\n",
    "\n",
    "                next_token_id = outputs[:, -1:]\n",
    "                input_ids = torch.cat([input_ids, next_token_id], dim=1)\n",
    "\n",
    "                # Update attention mask to include the new token\n",
    "                new_attention_mask = torch.ones((attention_mask.shape[0], 1), dtype=attention_mask.dtype, device=self.device)\n",
    "                attention_mask = torch.cat([attention_mask, new_attention_mask], dim=1)\n",
    "\n",
    "                # Stop if EOS token is generated\n",
    "                if next_token_id.item() == self.tokenizer.eos_token_id:\n",
    "                    print(f\"EOS token generated at iteration {i+1}\")\n",
    "                    break\n",
    "\n",
    "            # Record peak and current memory usage\n",
    "            peak_memory_lst.append(torch.cuda.max_memory_allocated(self.device))\n",
    "            cur_memory_lst.append(torch.cuda.memory_allocated(self.device))\n",
    "\n",
    "        # Decode generated text\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        print(f'Generated Text: {generated_text}')\n",
    "\n",
    "        # Adjust for pre-existing memory\n",
    "        prev_memory -= exist_memory\n",
    "        peak_memory_lst = [peak_memory - exist_memory for peak_memory in peak_memory_lst]\n",
    "        cur_memory_lst = [cur_memory - exist_memory for cur_memory in cur_memory_lst]\n",
    "\n",
    "        # Convert memory values to the specified unit\n",
    "        prev_memory = ModelMemoryUtilities.convert_memory(prev_memory, memory_unit)\n",
    "        peak_memory_lst = [ModelMemoryUtilities.convert_memory(mem, memory_unit) for mem in peak_memory_lst]\n",
    "        cur_memory_lst = [ModelMemoryUtilities.convert_memory(mem, memory_unit) for mem in cur_memory_lst]\n",
    "\n",
    "        return prev_memory, peak_memory_lst, cur_memory_lst\n",
    "\n",
    "    def test_cuda_training_memory(self, optimizer_type=torch.optim.Adam, max_iters = 1, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte' ):\n",
    "        device = self.device\n",
    "        self.model.cpu()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        exist_memory = torch.cuda.memory_allocated(device)\n",
    "        self.model.to(device)\n",
    "        self.model.train()\n",
    "        pre_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "        sample_inputs = self.simulate_input_ids(self.max_seq_len)\n",
    "        optimizer = optimizer_type(self.model.parameters(), lr=.001)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        peak_memory_dict = {\n",
    "            'forward': [],\n",
    "            'backward': [],\n",
    "            'optimizer': []\n",
    "            }\n",
    "\n",
    "        memory_dict =  {\n",
    "            'model_loading': None, \n",
    "            'forward_pass': [], \n",
    "            'backward_pass': [], \n",
    "            'optimize_model': []\n",
    "            }\n",
    "\n",
    "        for i in range(max_iters):\n",
    "            if use_amp:\n",
    "                with torch.amp.autocast(device_type=str(self.device)):\n",
    "                    output = self.model(**sample_inputs)\n",
    "                    output_logits = ModelMemoryUtilities.get_logits(output)\n",
    "                    output_logits_sum = output_logits.sum()\n",
    "                    forward_memory = torch.cuda.memory_allocated(device)\n",
    "                    forward_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "                    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "                output_logits_sum.backward()\n",
    "                backward_memory = torch.cuda.memory_allocated(device)\n",
    "                backward_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer_memory = torch.cuda.memory_allocated(device)\n",
    "                optimizer_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "            else:\n",
    "                output = self.model(**sample_inputs).sum()\n",
    "                output_logits = ModelMemoryUtilities.get_logits(output)\n",
    "                output_logits_sum = output_logits.sum()\n",
    "                forward_memory = torch.cuda.memory_allocated(self.device)\n",
    "                forward_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "                output_logits_sum.backward()\n",
    "                backward_memory = torch.cuda.memory_allocated(self.device)\n",
    "                backward_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer_memory = torch.cuda.memory_allocated(self.device)\n",
    "                optimizer_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "\n",
    "            pre_memory -= exist_memory\n",
    "            forward_memory -= exist_memory\n",
    "            forward_peak_memory -= exist_memory\n",
    "            backward_memory -= exist_memory\n",
    "            backward_peak_memory -= exist_memory\n",
    "            optimizer_memory -= exist_memory\n",
    "            optimizer_peak_memory -= exist_memory\n",
    "\n",
    "            peak_memory_dict['forward'].append(forward_peak_memory)\n",
    "            peak_memory_dict['backward'].append(backward_peak_memory)\n",
    "            peak_memory_dict['optimizer'].append(optimizer_peak_memory)\n",
    "\n",
    "            memory_dict['forward_pass'].append(forward_memory)\n",
    "            memory_dict['backward_pass'].append(backward_memory)\n",
    "            memory_dict['optimize_model'].append(optimizer_memory)\n",
    "\n",
    "        memory_dict['model_loading'] = pre_memory\n",
    "        filter_peak_memory_dict = {key: max(value) for key, value in peak_memory_dict.items()}\n",
    "        max_peak_stage, max_peak_memory = max(filter_peak_memory_dict.items(), key=lambda x: x[1])\n",
    "        memory_dict[f'max_peak_memory({max_peak_stage})'] = max_peak_memory\n",
    "        \n",
    "        print(f\"The training max peak memory: {ModelMemoryUtilities.convert_memory(max_peak_memory, memory_unit)} ({max_peak_stage} stage)\")\n",
    "        converted_memory_dict = {\n",
    "            key: [ModelMemoryUtilities.convert_memory(element, memory_unit) for element in value] if isinstance(value, list) else ModelMemoryUtilities.convert_memory(value, memory_unit)\n",
    "            for key, value in memory_dict.items()\n",
    "        }\n",
    "        print(f\"the training memory consumption: {converted_memory_dict}\")\n",
    "\n",
    "        return  converted_memory_dict\n",
    "    \n",
    "    def test_cpu_forward_memory(self, sample_inputs, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> Tuple[float, float, float]:\n",
    "        \"\"\"Estimate memory usage on CPU during a forward pass.\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        prev_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = self.model(**sample_inputs)\n",
    "\n",
    "        cur_memory = ModelMemoryUtilities.measure_cpu_memory() \n",
    "\n",
    "        prev_memory = ModelMemoryUtilities.convert_memory(prev_memory, memory_unit)\n",
    "        cur_memory = ModelMemoryUtilities.convert_memory(cur_memory, memory_unit)\n",
    "\n",
    "        print(f\"Previous Memory: {prev_memory:.2f} {memory_unit.upper()}; Current Memory: {cur_memory:.2f} {memory_unit.upper()}\")\n",
    "        \n",
    "        return prev_memory, cur_memory\n",
    "    \n",
    "    def test_cpu_iterative_inference_memory(self, prompt: str, max_iters: int = 100, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> Tuple[float, list, list]:\n",
    "        \"\"\"Estimate memory usage on CPU during iterative token-by-token generation.\"\"\"\n",
    "        self.model.eval()\n",
    "\n",
    "        prev_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_seq_len)\n",
    "        input_ids = inputs[\"input_ids\"].to(self.device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(self.device)\n",
    "\n",
    "        cur_memory_lst = []\n",
    "\n",
    "        for i in range(max_iters):\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    max_length=input_ids.shape[1] + 1,\n",
    "                    eos_token_id=self.tokenizer.eos_token_id,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                    do_sample=False\n",
    "                )\n",
    "                next_token_id = outputs[:, -1:]\n",
    "                input_ids = torch.cat([input_ids, next_token_id], dim=1)\n",
    "\n",
    "                # Update attention mask to include the new token\n",
    "                new_attention_mask = torch.ones((attention_mask.shape[0], 1), dtype=attention_mask.dtype, device=self.device)\n",
    "                attention_mask = torch.cat([attention_mask, new_attention_mask], dim=1)\n",
    "\n",
    "                if next_token_id.item() == self.tokenizer.eos_token_id:\n",
    "                    print(f\"EOS token generated at iteration {i+1}\")\n",
    "                    break\n",
    "\n",
    "            \n",
    "            cur_memory_lst.append(ModelMemoryUtilities.measure_cpu_memory())\n",
    "\n",
    "        # Decode generated text\n",
    "        generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        print(f'Generated Text: {generated_text}')\n",
    "\n",
    "        cur_memory_lst = [ModelMemoryUtilities.convert_memory(mem, memory_unit) for mem in cur_memory_lst]\n",
    "\n",
    "        return ModelMemoryUtilities.convert_memory(prev_memory, memory_unit),  cur_memory_lst\n",
    "    \n",
    "    def test_cpu_training_memory(self, optimizer_type=torch.optim.Adam, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte') -> Tuple[float, Dict[str, float]]:\n",
    "        \"\"\"Estimate memory usage on CPU during a training step (forward, backward, optimizer).\"\"\"\n",
    "        self.model.train()\n",
    "        prev_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "\n",
    "        sample_inputs = self.simulate_input_ids(self.max_seq_len)\n",
    "        optimizer = optimizer_type(self.model.parameters(), lr=0.001)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        forward_memory, backward_memory, optimizer_memory = 0, 0, 0\n",
    "\n",
    "        output_logits_sum = ModelMemoryUtilities.get_logits(self.model(**sample_inputs)).sum()\n",
    "        forward_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "\n",
    "        output_logits_sum.backward()\n",
    "        backward_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer_memory = ModelMemoryUtilities.measure_cpu_memory()\n",
    "\n",
    "\n",
    "\n",
    "        memory_dict = {\n",
    "            'model_loading': ModelMemoryUtilities.convert_memory(prev_memory, memory_unit),\n",
    "            'forward_pass': ModelMemoryUtilities.convert_memory(forward_memory, memory_unit),\n",
    "            'backward_pass': ModelMemoryUtilities.convert_memory(backward_memory, memory_unit),\n",
    "            'optimize_model': ModelMemoryUtilities.convert_memory(optimizer_memory, memory_unit)\n",
    "        }\n",
    "\n",
    "        print(f\"Training memory consumption: {memory_dict}\")\n",
    "\n",
    "        return  memory_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ModelMemoryMonitor:\n",
    "#     def __init__(self, model_name, batch_size=1, max_seq_len=4096, torch_dtype=torch.float16, use_amp=False, device=\"cuda\"):\n",
    "#         \"\"\"\n",
    "#         Initialize the ModelMemoryMonitor for tracking model inference memory usage.\n",
    "\n",
    "#         Args:\n",
    "#             model_name (str): Hugging Face model name or local path.\n",
    "#             batch_size (int): Number of samples in a batch.\n",
    "#             max_seq_len (int): Maximum sequence length.\n",
    "#             torch_dtype (torch.dtype): Data type (e.g., torch.float16).\n",
    "#             use_amp (bool): If True, enables mixed precision inference.\n",
    "#             device (str): Device for inference ('cuda' or 'cpu').\n",
    "#         \"\"\"\n",
    "#         self.model_name = model_name\n",
    "#         self.torch_dtype = torch_dtype\n",
    "#         self.device = device\n",
    "#         self.use_amp = use_amp\n",
    "#         self.batch_size = batch_size\n",
    "#         self.max_seq_len = max_seq_len\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "#         self.model = AutoModelForCausalLM.from_pretrained(self.model_name, torch_dtype=self.torch_dtype).to(device)\n",
    "\n",
    "#         # Set pad_token to eos_token if no padding token is available\n",
    "#         if self.tokenizer.pad_token is None:\n",
    "#             self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "#     def reinitialize_model(self):\n",
    "#         \"\"\"Reinitialize the model (useful for testing or resetting).\"\"\"\n",
    "#         self.model = AutoModelForCausalLM.from_pretrained(self.model_name, torch_dtype=self.torch_dtype).to(self.device)\n",
    "\n",
    "#     def delete_model(self):\n",
    "#         \"\"\"Delete the model and clear the GPU cache.\"\"\"\n",
    "#         del self.model\n",
    "#         gc.collect()\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"Model deleted and CUDA cache cleared.\")\n",
    "\n",
    "#     def convert_memory(self, memory, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte'):\n",
    "#         \"\"\"Convert memory to specified unit.\"\"\"\n",
    "#         if memory_unit == 'mb':\n",
    "#             return memory / 1048576  # Convert bytes to MB\n",
    "#         elif memory_unit == 'gb':\n",
    "#             return memory / 1073741824  # Convert bytes to GB\n",
    "#         return memory  # Default to bytes\n",
    "    \n",
    "#     def get_logits(self, model_output):\n",
    "#         \"\"\"\n",
    "#         Extracts logits from the model output. Supports different output types.\n",
    "\n",
    "#             Args:\n",
    "#             model_output: Output from the model's forward pass.\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: The logits tensor.\n",
    "\n",
    "#         Raises:\n",
    "#             ValueError: If logits cannot be found in the output.\n",
    "#         \"\"\"\n",
    "#         # Check for `logits` attribute (used by most Hugging Face models)\n",
    "#         if hasattr(model_output, 'logits'):\n",
    "#             return model_output.logits\n",
    "#         # If the output is directly a tensor, assume it's the logits\n",
    "#         elif isinstance(model_output, torch.Tensor):\n",
    "#             return model_output\n",
    "#         else:\n",
    "#             raise ValueError(\"Model output does not contain logits or is not a tensor.\")\n",
    "\n",
    "\n",
    "#     def simulate_input_ids(self, sequence_length: int, only_padding=False):\n",
    "#         \"\"\"\n",
    "#         Generate dummy input IDs of specified sequence length.\n",
    "\n",
    "#         Args:\n",
    "#             sequence_length (int): Desired sequence length for input IDs.\n",
    "#             only_padding (bool): If True, generates only padding tokens.\n",
    "\n",
    "#         Returns:\n",
    "#             dict: A dictionary with input IDs and attention masks on the specified device.\n",
    "#         \"\"\"\n",
    "#         dummy_text = \"\" if only_padding else \" \".join([\"token\"] * int(sequence_length * 1.5))\n",
    "#         inputs = self.tokenizer(dummy_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_seq_len)\n",
    "#         inputs = {key: value.to(self.device) for key, value in inputs.items()}\n",
    "\n",
    "#         # Validate sequence length and attention mask sum\n",
    "#         actual_length = inputs[\"input_ids\"].shape[1]\n",
    "#         if actual_length != sequence_length:\n",
    "#             print(f\"Warning: Expected sequence length ({sequence_length}) does not match actual input length ({actual_length}).\")\n",
    "\n",
    "#         attention_mask_sum = inputs[\"attention_mask\"].sum().item()\n",
    "#         if attention_mask_sum != sequence_length:\n",
    "#             print(f\"Warning: Attention mask sum ({attention_mask_sum}) does not match expected sequence length ({sequence_length}).\")\n",
    "\n",
    "#         return inputs\n",
    "\n",
    "#     def test_forward_memory(self, sample_inputs, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte'):\n",
    "#         \"\"\"\n",
    "#         Estimate memory usage during a forward pass.\n",
    "\n",
    "#         Args:\n",
    "#             sample_inputs (dict): Input data for the model.\n",
    "#             memory_unit (Literal['byte', 'mb', 'gb']): Unit of memory measurement ('byte', 'mb', 'gb').\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: Previous, peak, and current memory in the specified unit.\n",
    "#         \"\"\"\n",
    "#         self.model.cpu()\n",
    "#         exist_memory = torch.cuda.memory_allocated(self.device)\n",
    "#         self.model.to(self.device)\n",
    "#         self.model.eval()\n",
    "\n",
    "#         # Track initial memory usage\n",
    "#         prev_memory = torch.cuda.memory_allocated(self.device)\n",
    "#         torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "#         # Perform inference with optional AMP (mixed precision)\n",
    "#         with torch.no_grad():\n",
    "#             if self.use_amp:\n",
    "#                 with torch.amp.autocast(device_type=str(self.device)):\n",
    "#                     outputs = self.model(**sample_inputs)\n",
    "#             else:\n",
    "#                 outputs = self.model(**sample_inputs)\n",
    "\n",
    "#         # Get peak and current memory usage\n",
    "#         peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "#         cur_memory = torch.cuda.memory_allocated(self.device)\n",
    "\n",
    "#         # delete pre-existing memory\n",
    "#         prev_memory -= exist_memory\n",
    "#         peak_memory -= exist_memory\n",
    "#         cur_memory -= exist_memory\n",
    "\n",
    "#         # Convert memory measurements to the specified unit\n",
    "#         prev_memory = self.convert_memory(prev_memory, memory_unit)\n",
    "#         peak_memory = self.convert_memory(peak_memory, memory_unit)\n",
    "#         cur_memory = self.convert_memory(cur_memory, memory_unit)\n",
    "\n",
    "#         # Display memory usage summary\n",
    "#         print(f\"Previous Memory: {prev_memory:.2f} {memory_unit.upper()}; Peak Memory: {peak_memory:.2f} {memory_unit.upper()}; Current Memory: {cur_memory:.2f} {memory_unit.upper()}\")\n",
    "#         print(f\"Peak Memory Difference: {peak_memory - prev_memory:.2f} {memory_unit.upper()}\")\n",
    "#         print(f\"Total Memory Consumption: {cur_memory - prev_memory:.2f} {memory_unit.upper()}\")\n",
    "\n",
    "#         return prev_memory, peak_memory, cur_memory\n",
    "\n",
    "#     def test_iterative_inference_memory(self, prompt, max_iters=100):\n",
    "#         \"\"\"\n",
    "#         Estimate memory usage during iterative token-by-token generation.\n",
    "\n",
    "#         Args:\n",
    "#             prompt (str): Initial prompt for generation.\n",
    "#             max_iters (int): Maximum number of iterations (tokens) to generate.\n",
    "\n",
    "#         Returns:\n",
    "#             tuple: Initial memory, list of peak memory per iteration, list of current memory per iteration.\n",
    "#         \"\"\"\n",
    "#         self.model.cpu()\n",
    "#         exist_memory = torch.cuda.memory_allocated(self.device)\n",
    "#         self.model.to(self.device)\n",
    "#         self.model.eval()\n",
    "#         prev_memory = torch.cuda.memory_allocated(self.device)\n",
    "#         inputs = self.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=self.max_seq_len)\n",
    "#         input_ids = inputs[\"input_ids\"].to(self.device)\n",
    "#         attention_mask = inputs[\"attention_mask\"].to(self.device) \n",
    "\n",
    "#         peak_memory_lst, cur_memory_lst = [], []\n",
    "\n",
    "#         for i in range(max_iters):\n",
    "#             torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 if self.use_amp:\n",
    "#                     with torch.amp.autocast(device_type=str(self.device)):\n",
    "#                         outputs = self.model.generate(\n",
    "#                             input_ids,\n",
    "#                             attention_mask=attention_mask,\n",
    "#                             max_length=input_ids.shape[1] + 1,\n",
    "#                             eos_token_id=self.tokenizer.eos_token_id,\n",
    "#                             pad_token_id=self.tokenizer.eos_token_id,\n",
    "#                             do_sample=False\n",
    "#                         )\n",
    "#                 else:\n",
    "#                     outputs = self.model.generate(\n",
    "#                         input_ids,\n",
    "#                         attention_mask=attention_mask,\n",
    "#                         max_length=input_ids.shape[1] + 1,\n",
    "#                         eos_token_id=self.tokenizer.eos_token_id,\n",
    "#                         pad_token_id=self.tokenizer.eos_token_id,\n",
    "#                         do_sample=False\n",
    "#                     )\n",
    "\n",
    "#                 next_token_id = outputs[:, -1:]\n",
    "#                 input_ids = torch.cat([input_ids, next_token_id], dim=1)\n",
    "\n",
    "#                 # Update attention mask to include the new token\n",
    "#                 new_attention_mask = torch.ones((attention_mask.shape[0], 1), dtype=attention_mask.dtype, device=self.device)\n",
    "#                 attention_mask = torch.cat([attention_mask, new_attention_mask], dim=1)\n",
    "\n",
    "#                 if next_token_id.item() == self.tokenizer.eos_token_id:\n",
    "#                     print(f\"EOS token generated at iteration {i+1}\")\n",
    "#                     break\n",
    "\n",
    "#             peak_memory_lst.append(torch.cuda.max_memory_allocated(self.device))\n",
    "#             cur_memory_lst.append(torch.cuda.memory_allocated(self.device))\n",
    "\n",
    "#         generated_text = self.tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "#         print(f'Generated Text: {generated_text}')\n",
    "\n",
    "#         # - delete pre-existing memory\n",
    "#         prev_memory -= exist_memory\n",
    "#         peak_memory_lst = [peak_memory - exist_memory for peak_memory in peak_memory_lst]\n",
    "#         cur_memory_lst = [cur_memory - exist_memory for cur_memory in cur_memory_lst]\n",
    "\n",
    "#         return prev_memory, peak_memory_lst, cur_memory_lst\n",
    "    \n",
    "    # def test_training_memory(self, optimizer_type=torch.optim.Adam, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte' ):\n",
    "    #     device = self.device\n",
    "    #     self.model.cpu()\n",
    "    #     torch.cuda.reset_peak_memory_stats()\n",
    "    #     exist_memory = torch.cuda.memory_allocated(device)\n",
    "    #     self.model.to(device)\n",
    "    #     self.model.train()\n",
    "    #     pre_memory = torch.cuda.memory_allocated(device)\n",
    "\n",
    "    #     sample_inputs = self.simulate_input_ids(self.max_seq_len)\n",
    "    #     optimizer = optimizer_type(self.model.parameters(), lr=.001)\n",
    "\n",
    "    #     optimizer.zero_grad()\n",
    "\n",
    "    #     if use_amp:\n",
    "    #         with torch.amp.autocast(device_type=str(self.device)):\n",
    "    #             output = self.model(**sample_inputs)\n",
    "    #             output_logits = self.get_logits(output)\n",
    "    #             output_logits_sum = output_logits.sum()\n",
    "    #             forward_memory = torch.cuda.memory_allocated(device)\n",
    "    #             forward_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "    #             torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    #         output_logits_sum.backward()\n",
    "    #         backward_memory = torch.cuda.memory_allocated(device)\n",
    "    #         backward_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "    #         torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    #         optimizer.step()\n",
    "    #         optimizer_memory = torch.cuda.memory_allocated(device)\n",
    "    #         optimizer_peak_memory = torch.cuda.max_memory_allocated(device)\n",
    "\n",
    "\n",
    "    #     else:\n",
    "    #         # Forward pass without AMP\n",
    "    #         output = self.model(**sample_inputs).sum()\n",
    "    #         forward_memory = torch.cuda.memory_allocated(self.device)\n",
    "    #         forward_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "    #         torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    #         # Backward pass without AMP\n",
    "    #         output.backward()\n",
    "    #         backward_memory = torch.cuda.memory_allocated(self.device)\n",
    "    #         backward_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "    #         torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    #         # Optimizer step without AMP\n",
    "    #         optimizer.step()\n",
    "    #         optimizer_memory = torch.cuda.memory_allocated(self.device)\n",
    "    #         optimizer_peak_memory = torch.cuda.max_memory_allocated(self.device)\n",
    "\n",
    "    #     # - delete existing memory\n",
    "    #     pre_memory -= exist_memory\n",
    "    #     forward_memory -= exist_memory\n",
    "    #     forward_peak_memory -= exist_memory\n",
    "    #     backward_memory -= exist_memory\n",
    "    #     backward_peak_memory -= exist_memory\n",
    "    #     optimizer_memory -= exist_memory\n",
    "    #     optimizer_peak_memory -= exist_memory\n",
    "\n",
    "    #     peak_memory_dict = {\n",
    "    #         'forward': forward_peak_memory,\n",
    "    #         'backward': backward_peak_memory,\n",
    "    #         'optimizer': optimizer_peak_memory\n",
    "    #     }\n",
    "\n",
    "        \n",
    "    #     max_peak_stage, max_peak_memory = max(peak_memory_dict.items(), key=lambda x: x[1])\n",
    "        \n",
    "    #     memory_dict = {'model_loading': pre_memory, 'forward_pass': forward_memory, 'backward_pass': backward_memory, 'optimize_model': optimizer_memory }\n",
    "\n",
    "    #     print(f\"The training max peak memory: {self.convert_memory(max_peak_memory, memory_unit)} ({max_peak_stage} stage)\")\n",
    "    #     converted_memory_dict = {key: self.convert_memory(value, memory_unit) for key, value in memory_dict.items()}\n",
    "    #     print(f\"the training memory consumption: {converted_memory_dict}\")\n",
    "\n",
    "    #     return max_peak_memory, memory_dict\n",
    "\n",
    "\n",
    "#     def draw_memory_lines(self, prev_memory, peak_memory_lst, cur_memory_lst, memory_unit: Literal['byte', 'mb', 'gb'] = 'byte'):\n",
    "#         \"\"\"\n",
    "#         Plot memory usage over iterations.\n",
    "\n",
    "#         Args:\n",
    "#             prev_memory (int): Baseline memory usage.\n",
    "#             peak_memory_lst (list[int]): List of peak memory usage per iteration.\n",
    "#             cur_memory_lst (list[int]): List of current memory usage per iteration.\n",
    "#             memory_unit (Literal['byte', 'mb', 'gb']): Unit for memory measurements ('byte', 'mb', 'gb').\n",
    "#         \"\"\"\n",
    "#         conv_prev_memory = self.convert_memory(prev_memory, memory_unit)\n",
    "#         conv_peak_memory = [self.convert_memory(peak, memory_unit) for peak in peak_memory_lst]\n",
    "#         conv_cur_memory = [self.convert_memory(cur, memory_unit) for cur in cur_memory_lst]\n",
    "\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         iterations = range(len(peak_memory_lst))\n",
    "\n",
    "#         # Baseline memory line\n",
    "#         plt.axhline(y=conv_prev_memory, color='gray', linestyle='--', linewidth=1.5, label=f'Baseline ({conv_prev_memory:.2f} {memory_unit.upper()})')\n",
    "\n",
    "#         # Peak and current memory lines\n",
    "#         plt.plot(iterations, conv_peak_memory, label='Peak Memory', color='#FF5733', linewidth=2.5, linestyle='-', marker='o', markersize=5, alpha=0.85)\n",
    "#         plt.plot(iterations, conv_cur_memory, label='Current Memory', color='#3498DB', linewidth=2.5, linestyle='-', marker='x', markersize=5, alpha=0.85)\n",
    "\n",
    "#         # Labels and title\n",
    "#         plt.xlabel(\"Iterations\", fontsize=12)\n",
    "#         plt.ylabel(f\"Memory Usage ({memory_unit.upper()})\", fontsize=12)\n",
    "#         plt.title(\"Memory Usage per Iteration\", fontsize=16, fontweight='bold')\n",
    "#         plt.legend()\n",
    "#         plt.grid(True, linestyle='--', linewidth=0.6, alpha=0.7)\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - Test estimate forward memory method\n",
    "# monitor = ModelMemoryMonitor(llama7b_model_name, use_amp=use_amp, device=device)\n",
    "# sample_inputs = monitor.simulate_input_ids(1)\n",
    "# monitor.test_cuda_forward_memory(sample_inputs, memory_unit='mb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test estimate inference memory method\n",
    "# prompt = (\n",
    "#     'You should generate 100 words to explain diffusion model: '\n",
    "# )\n",
    "# monitor = ModelMemoryMonitor(llama7b_model_name, use_amp=use_amp, device=device)\n",
    "# prev_memory, peak_memory_lst, cur_memory_lst = monitor.test_cuda_iterative_inference_memory(prompt)\n",
    "# ModelMemoryUtilities.draw_memory_lines(prev_memory, cur_memory_lst, peak_memory_lst, memory_unit='gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test test training memory method\n",
    "# monitor = ModelMemoryMonitor(tinyllama_model_name, use_amp=use_amp, device=device)\n",
    "# memory_dict = monitor.test_cuda_training_memory(max_iters=10)\n",
    "# ModelMemoryUtilities.draw_memory_from_dict(memory_dict, memory_unit='gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Start to CPU test\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test cpu test forward memory method\n",
    "# monitor = ModelMemoryMonitorCPU(tinyllama_model_name, device=device)\n",
    "# sample_inputs = monitor.simulate_input_ids(1)\n",
    "# monitor.test_cpu_forward_memory(sample_inputs, memory_unit='gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93bec7c097a54feaa922dcb27feba4cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuz165/LLM-Simulator/llm-simulator-env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/home/yuz165/LLM-Simulator/llm-simulator-env/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:595: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test cpu inference memory method\n",
    "prompt = (\n",
    "    'You should generate 100 words to explain diffusion model: '\n",
    ")\n",
    "monitor = ModelMemoryMonitorCPU(llama7b_model_name, device=device)\n",
    "prev_memory, peak_memory_lst, cur_memory_lst = monitor.test_cpu_iterative_inference_memory(prompt, max_iters= 5)\n",
    "\n",
    "ModelMemoryUtilities.draw_memory_lines(prev_memory, cur_memory_lst, peak_memory_lst=peak_memory_lst, memory_unit='gb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training memory consumption: {'model_loading': 569044992, 'forward_pass': [21660180480, 31230853120, 31616229376], 'backward_pass': [10413879296, 20089475072, 19834167296], 'optimize_model': [19345641472, 20089724928, 19834257408], 'max_peak_memory(forward)': [21660180480, 31230853120, 31616229376]}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m monitor \u001b[38;5;241m=\u001b[39m ModelMemoryMonitorCPU(tinyllama_model_name, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m memory_dict \u001b[38;5;241m=\u001b[39m monitor\u001b[38;5;241m.\u001b[39mtest_cpu_training_memory(max_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mModelMemoryUtilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_memory_from_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemory_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 68\u001b[0m, in \u001b[0;36mModelMemoryUtilities.draw_memory_from_dict\u001b[0;34m(memory_dict, memory_unit)\u001b[0m\n\u001b[1;32m     65\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Extract and plot fixed lines for 'model_loading' and any 'max_peak_memory'\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m fixed_lines \u001b[38;5;241m=\u001b[39m {key: ModelMemoryUtilities\u001b[38;5;241m.\u001b[39mconvert_memory(value, memory_unit) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m memory_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     69\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_peak_memory\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_loading\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m fixed_lines\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     71\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mvalue, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmemory_unit\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 68\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     65\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Extract and plot fixed lines for 'model_loading' and any 'max_peak_memory'\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m fixed_lines \u001b[38;5;241m=\u001b[39m {key: \u001b[43mModelMemoryUtilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_unit\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m memory_dict\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     69\u001b[0m                \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_peak_memory\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_loading\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m fixed_lines\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     71\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxhline(y\u001b[38;5;241m=\u001b[39mvalue, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, linewidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmemory_unit\u001b[38;5;241m.\u001b[39mupper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m, in \u001b[0;36mModelMemoryUtilities.convert_memory\u001b[0;34m(memory, memory_unit)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memory \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1048576\u001b[39m  \u001b[38;5;66;03m# Convert bytes to MB\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m memory_unit \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgb\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmemory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1073741824\u001b[39;49m  \u001b[38;5;66;03m# Convert bytes to GB\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m memory\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test test training memory method\n",
    "monitor = ModelMemoryMonitorCPU(tinyllama_model_name, device=device)\n",
    "memory_dict = monitor.test_cpu_training_memory(max_iters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ModelMemoryUtilities.draw_memory_from_dict(memory_dict, memory_unit='gb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-simulator-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
